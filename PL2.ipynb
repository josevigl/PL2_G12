{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos del equipo (COMPLETAR)\n",
    "\n",
    "Identificador de grupo: Grupo XX.\n",
    "\n",
    "| Nombre y apellido | % de contribución |\n",
    "|-------------------|-------------------|\n",
    "|                   |                   |\n",
    "|                   |                   |\n",
    "|                   |                   |\n",
    "|                   |                   |\n",
    "|                   |                   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. INSTALACIÓN Y CONFIGURACIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch torchvision hypothesis adversarial-robustness-toolbox adversarial-robustness-toolbox[pytorch] scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CONFIGURACIÓN INICIAL Y CARGA DE LIBRERÍAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn\n",
    "\n",
    "from hypothesis import given, strategies as st, settings\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.attacks.evasion import FastGradientMethod, ProjectedGradientDescent\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Reproducibilidad\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "sklearn.random.seed(SEED)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Usando: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DATOS Y MODELO BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type: ignore\n",
    "\n",
    "# Cargar MNIST (versión simplificada, mitad del dataset)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_full = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_full = datasets.MNIST('./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_indices = np.random.choice(len(train_full), 30000, replace=False)\n",
    "test_indices = np.random.choice(len(test_full), 5000, replace=False)\n",
    "\n",
    "train_subset = Subset(train_full, train_indices)\n",
    "test_subset = Subset(test_full, test_indices)\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_subset, batch_size=128, shuffle=False)\n",
    "\n",
    "print(f\"Train: {len(train_subset)}, Test: {len(test_subset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo simple\n",
    "class SimpleNN(nn.Module):\n",
    "    \"\"\"Red neuronal simple para MNIST\"\"\"\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "\n",
    "        # Capa 1\n",
    "        self.flatten = nn.Flatten()         # [1,28,28] → [784]\n",
    "        self.fc1 = nn.Linear(28*28, 128)    # [784] → [128]\n",
    "        self.relu1 = nn.ReLU()              # Activación no-lineal\n",
    "        self.dropout1 = nn.Dropout(0.2)     # Regularización\n",
    "\n",
    "        # Capa 2\n",
    "        self.fc2 = nn.Linear(128, 64)   # [128] → [64]\n",
    "        self.relu2 = nn.ReLU()          # Activación no-lineal\n",
    "        self.dropout2 = nn.Dropout(0.2) # Regularización\n",
    "\n",
    "        # Capa salida\n",
    "        self.fc3 = nn.Linear(64, 10) # [64] → [10] (10 clases)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = SimpleNN().to(device)\n",
    "print(f\"Parámetros: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, epochs=3):\n",
    "    \"\"\"Entrena el modelo\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f'  Batch {batch_idx}/{len(train_loader)}, '\n",
    "                      f'Loss: {loss.item():.4f}')\n",
    "\n",
    "        acc = 100. * correct / total\n",
    "        print(f'Época {epoch+1}: Loss: {running_loss/len(train_loader):.3f}, '\n",
    "              f'Accuracy: {acc:.1f}%')\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_simple(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "print(\"Entrenando modelo baseline...\")\n",
    "train_model(model, train_loader, epochs=5)\n",
    "acc = evaluate_simple(model, test_loader)\n",
    "print(f\"\\nAccuracy: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PROPERTY-BASED TESTING (I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type: ignore\n",
    "\n",
    "def predict_single(model, image):\n",
    "    \"\"\"Predice una imagen y retorna clase y confianza\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if len(image.shape) == 3:\n",
    "            image = image.unsqueeze(0)\n",
    "        image = image.to(device)\n",
    "        output = model(image)\n",
    "        probs = F.softmax(output, dim=1)\n",
    "        pred_class = torch.argmax(probs, dim=1).item()\n",
    "        confidence = probs[0, pred_class].item()\n",
    "    return pred_class, confidence\n",
    "\n",
    "@given(st.integers(min_value=0, max_value=len(test_subset)-1))\n",
    "@settings(max_examples=20, deadline=None)\n",
    "def test_consistency(idx):\n",
    "    # EJERCICIO 1: Verifica que dos predicciones de la misma imagen sean idénticas.\n",
    "    # 1. Obtener imagen\n",
    "    # 2. Predecir dos veces\n",
    "    # 3. Verificar con assert\n",
    "    # === INICIO SOLUCIÓN ===\n",
    "\n",
    "    # === FIN SOLUCIÓN ===\n",
    "    pass\n",
    "\n",
    "# Ejecutar test\n",
    "try:\n",
    "    test_consistency()\n",
    "    print(\"✅ Test de consistencia: PASADO\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Test fallado: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. PROPERTY-BASED TESTING (II)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type: ignore\n",
    "\n",
    "@given(\n",
    "    st.integers(min_value=0, max_value=len(test_subset)-1),\n",
    "    st.floats(min_value=0.01, max_value=0.3)\n",
    ")\n",
    "@settings(max_examples=15, deadline=None)\n",
    "def test_noise_robustness(idx, noise_std):\n",
    "    # EJERCICIO 2: Verifica que un pequeño ruido no destruya la confianza del modelo.\n",
    "    # 1. Obtener imagen\n",
    "    # 2. Crear imagen con ruido, por ejemplo: image_noisy = image + torch.randn_like(image) * noise_std\n",
    "    # 3. Predecir ambas\n",
    "    # 4. Verificar que la confianza no baja más de un 50% con respecto de la original\n",
    "    # === INICIO SOLUCIÓN ===\n",
    "\n",
    "    # === FIN SOLUCIÓN ===\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    test_noise_robustness()\n",
    "    print(\"✅ Test de ruido: PASADO\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Test fallado: {str(e)[:80]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. VALIDACIÓN ESTADÍSTICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener predicciones para bootstrap\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "def bootstrap_accuracy(preds, labels, n_iterations=1000):\n",
    "    # EJERCICIO 3: Calcula intervalo de confianza 95% para accuracy.\n",
    "    # 1. Crear lista vacía: accuracies = []\n",
    "    # 2. Iterar n_iterations veces\n",
    "    # 3. Resamplear: indices = resample(range(len(preds)), n_samples=len(preds))\n",
    "    # 4. Calcular accuracy: acc = accuracy_score(labels[indices], preds[indices])\n",
    "    # 5. Añadir accuracy a la lista\n",
    "    # 6. Retornar tupla (media, percentil 2.5, percentil 97.5)\n",
    "    # === INICIO SOLUCIÓN ===\n",
    "\n",
    "    # === FIN SOLUCIÓN ===\n",
    "    pass\n",
    "\n",
    "# Ejecutar bootstrap\n",
    "print(\"Calculando bootstrap...\")\n",
    "mean, lower, upper = bootstrap_accuracy(all_preds, all_labels, n_iterations=1000)\n",
    "print(f\"\\nAccuracy: {mean*100:.2f}% [IC 95%: {lower*100:.2f}% - {upper*100:.2f}%]\")\n",
    "print(f\"Ancho del intervalo: {(upper-lower)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. COMPARACIÓN CON BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulamos un segundo modelo (copia con ruido en predicciones)\n",
    "# En la práctica real, serían predicciones de otro modelo\n",
    "model2_preds = all_preds.copy()\n",
    "# Simular que el modelo 2 comete algunos errores diferentes\n",
    "flip_indices = np.random.choice(len(model2_preds), size=50, replace=False)\n",
    "model2_preds[flip_indices] = (model2_preds[flip_indices] + 1) % 10\n",
    "\n",
    "def compare_models(preds1, preds2, labels):\n",
    "    # EJERCICIO 4: Compara estadísticamente dos modelos.\n",
    "    # 1. Calcular bootstrap para modelo 1 con 500 iteraciones\n",
    "    # 2. Calcular bootstrap para modelo 2 con 500 iteraciones\n",
    "    # 3. Comprobar si intervalos NO se solapan (no_overlap)\n",
    "    # 4. Retornar no_overlap y ambas medias\n",
    "    # === INICIO SOLUCIÓN ===\n",
    "\n",
    "    # === FIN SOLUCIÓN ===\n",
    "    pass\n",
    "\n",
    "print(\"Comparando modelos...\")\n",
    "different, acc1, acc2 = compare_models(all_preds, model2_preds, all_labels)\n",
    "print(f\"\\nModelo 1: {acc1*100:.2f}%\")\n",
    "print(f\"Modelo 2: {acc2*100:.2f}%\")\n",
    "print(f\"¿Son significativamente diferentes? {'SÍ' if different else 'NO'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. EVALUACIÓN ADVERSARIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type: ignore\n",
    "\n",
    "# Preparar datos sin normalización para ART\n",
    "transform_art = transforms.ToTensor()\n",
    "test_art = datasets.MNIST('./data', train=False, transform=transform_art)\n",
    "test_subset_art = Subset(test_art, test_indices[:500])  # Solo 500 para rapidez\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "for img, label in test_subset_art:\n",
    "    X_test.append(img.numpy())\n",
    "    y_test.append(label)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(f\"Datos para ART: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper para ART (normaliza internamente)\n",
    "class ModelWrapper(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Normalizar\n",
    "        x = (x - 0.1307) / 0.3081\n",
    "        return self.model(x)\n",
    "\n",
    "wrapped = ModelWrapper(model)\n",
    "\n",
    "# Crear clasificador ART\n",
    "classifier = PyTorchClassifier(\n",
    "    model=wrapped,\n",
    "    loss=nn.CrossEntropyLoss(),\n",
    "    optimizer=optim.Adam(model.parameters()),\n",
    "    input_shape=(1, 28, 28),\n",
    "    nb_classes=10,\n",
    "    clip_values=(0.0, 1.0)\n",
    ")\n",
    "\n",
    "print(\"✅ Clasificador ART listo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ATAQUE FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fgsm(classifier, X_test, y, epsilon=0.3):\n",
    "    # EJERCICIO 5: Evalúa robustez con ataque FGSM.\n",
    "    # 1. Crear ataque indicando solo estimator y eps\n",
    "    # 2. Generar adversarios X_adv (usar X_test como input)\n",
    "    # 3. Predecir ambos (limpios y adversarios) y calcular accuracies\n",
    "    # 4. Retornar acc_clean, acc_adv\n",
    "    # === INICIO SOLUCIÓN ===\n",
    "\n",
    "    # === FIN SOLUCIÓN ===\n",
    "    pass\n",
    "\n",
    "print(\"Ejecutando ataque FGSM...\")\n",
    "clean_acc, adv_acc = evaluate_fgsm(classifier, X_test, y_test, epsilon=0.3)\n",
    "print(f\"\\nAccuracy limpia: {clean_acc:.2f}%\")\n",
    "print(f\"Accuracy adversaria (FGSM): {adv_acc:.2f}%\")\n",
    "print(f\"Caída: {clean_acc - adv_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ATAQUE PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pgd(classifier, X, y, epsilon=0.3):\n",
    "    # EJERCICIO 6: Evalúa robustez con ataque PGD.\n",
    "    # 1. Crear ataque indicando solo estimator, eps, eps step (epsilon/10) y 40 iteraciones\n",
    "    # 2. Generar y evaluar como en FGSM\n",
    "    # 3. Retornar acc_clean, acc_adv\n",
    "    # === INICIO SOLUCIÓN ===\n",
    "\n",
    "    # === FIN SOLUCIÓN ===\n",
    "    pass\n",
    "\n",
    "print(\"Ejecutando ataque PGD...\")\n",
    "clean_acc_pgd, adv_acc_pgd = evaluate_pgd(classifier, X_test, y_test, epsilon=0.3)\n",
    "print(f\"\\nAccuracy limpia: {clean_acc_pgd:.2f}%\")\n",
    "print(f\"Accuracy adversaria (PGD): {adv_acc_pgd:.2f}%\")\n",
    "print(f\"Caída: {clean_acc_pgd - adv_acc_pgd:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ADVERSARIAL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type: ignore\n",
    "\n",
    "from art.defences.trainer import AdversarialTrainer\n",
    "\n",
    "# Preparar datos para adversarial training\n",
    "print(\"\\nPreparando datos para adversarial training...\")\n",
    "\n",
    "# Preparar datos de train para ART\n",
    "train_art = datasets.MNIST('./data', train=True, transform=transforms.ToTensor())\n",
    "train_subset_art = Subset(train_art, train_indices)\n",
    "train_loader_art = DataLoader(train_subset_art, batch_size=128, shuffle=True)\n",
    "\n",
    "# Extraer datos de entrenamiento en formato numpy\n",
    "X_train = []\n",
    "y_train = []\n",
    "for img, label in train_subset_art:\n",
    "    X_train.append(img.numpy())\n",
    "    y_train.append(label)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "print(f\"Datos de entrenamiento: {X_train.shape}\")\n",
    "\n",
    "# Crear nuevo modelo robusto\n",
    "robust_model = SimpleNN().to(device)\n",
    "wrapped_robust = ModelWrapper(robust_model)\n",
    "\n",
    "# Crear clasificador para adversarial training\n",
    "classifier_robust = PyTorchClassifier(\n",
    "    model=wrapped_robust,\n",
    "    loss=nn.CrossEntropyLoss(),\n",
    "    optimizer=optim.Adam(robust_model.parameters(), lr=0.001),\n",
    "    input_shape=(1, 28, 28),\n",
    "    nb_classes=10,\n",
    "    clip_values=(0.0, 1.0)\n",
    ")\n",
    "\n",
    "attack_train = FastGradientMethod(estimator=classifier_robust, eps=0.1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ADVERSARIAL TRAINING\")\n",
    "print(\"=\"*70)\n",
    "print(\"Entrenando modelo robusto...\\n\")\n",
    "\n",
    "# EJERCICIO 7: Entrenar modelo con ejemplos adversarios.\n",
    "# 1. Crear AdversarialTrainer indicando classifier, attack_train y ratio=0.5\n",
    "# 2. Entrenar con fit usando X_train, y_train, nb_epochs=3, batch_size=128\n",
    "# === INICIO SOLUCIÓN ===\n",
    "\n",
    "# === FIN SOLUCIÓN ===\n",
    "\n",
    "print(\"\\n✅ Adversarial training completado\")\n",
    "\n",
    "# Evaluar modelo robusto en datos limpios\n",
    "print(\"\\nEvaluando modelo robusto...\")\n",
    "acc_robust = evaluate_simple(robust_model, test_loader)\n",
    "print(f\"Accuracy en test limpio: {acc_robust:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. COMPARACIÓN FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar modelo robusto\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARACIÓN: BASELINE VS ROBUSTO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear clasificador para modelo robusto\n",
    "wrapped_robust_eval = ModelWrapper(robust_model)\n",
    "classifier_robust_eval = PyTorchClassifier(\n",
    "    model=wrapped_robust_eval,\n",
    "    loss=nn.CrossEntropyLoss(),\n",
    "    optimizer=optim.Adam(robust_model.parameters()),\n",
    "    input_shape=(1, 28, 28),\n",
    "    nb_classes=10,\n",
    "    clip_values=(0.0, 1.0)\n",
    ")\n",
    "\n",
    "# Evaluar ambos modelos\n",
    "print(\"\\nModelo BASELINE:\")\n",
    "base_clean, base_fgsm = evaluate_fgsm(classifier, X_test, y_test, 0.3)\n",
    "_, base_pgd = evaluate_pgd(classifier, X_test, y_test, 0.3)\n",
    "print(f\"  Limpia: {base_clean:.2f}%\")\n",
    "print(f\"  FGSM:   {base_fgsm:.2f}%\")\n",
    "print(f\"  PGD:    {base_pgd:.2f}%\")\n",
    "\n",
    "print(\"\\nModelo ROBUSTO:\")\n",
    "rob_clean, rob_fgsm = evaluate_fgsm(classifier_robust_eval, X_test, y_test, 0.3)\n",
    "_, rob_pgd = evaluate_pgd(classifier_robust_eval, X_test, y_test, 0.3)\n",
    "print(f\"  Limpia: {rob_clean:.2f}%\")\n",
    "print(f\"  FGSM:   {rob_fgsm:.2f}%\")\n",
    "print(f\"  PGD:    {rob_pgd:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MEJORAS:\")\n",
    "print(f\"  Limpia: {rob_clean - base_clean:+.2f}%\")\n",
    "print(f\"  FGSM:   {rob_fgsm - base_fgsm:+.2f}%\")\n",
    "print(f\"  PGD:    {rob_pgd - base_pgd:+.2f}%\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type: ignore\n",
    "\n",
    "# Visualización final\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "metrics = ['Limpia', 'FGSM', 'PGD']\n",
    "baseline_scores = [base_clean, base_fgsm, base_pgd]\n",
    "robust_scores = [rob_clean, rob_fgsm, rob_pgd]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars1 = ax.bar(x - width/2, baseline_scores, width, label='Baseline', color='lightcoral')\n",
    "bars2 = ax.bar(x + width/2, robust_scores, width, label='Robusto', color='lightgreen')\n",
    "\n",
    "ax.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax.set_title('Comparación: Modelo Baseline vs Robusto', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Añadir valores sobre barras\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. EJERCICIO 8\n",
    "\n",
    "Responde a las siguientes preguntas en cada una de las propias celdas Markdown\n",
    "del Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Property-Based Testing\n",
    "\n",
    "- ¿Pasaron ambos tests (ruido y consistencia)? Si alguno falló, ¿por qué crees que ocurrió?\n",
    "    > [Respuesta]\n",
    "\n",
    "- ¿Qué ventaja tiene usar Hypothesis vs. tests manuales?\n",
    "    > [Respuesta]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Validación Estadística\n",
    "\n",
    "- ¿Cuál es el intervalo de confianza de la accuracy? ¿Es estrecho o amplio?\n",
    "    > [Respuesta]\n",
    "\n",
    "- ¿Por qué es importante reportar intervalos y no solo la media?\n",
    "    > [Respuesta]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Robustez Adversaria\n",
    "\n",
    "- ¿Cuánto cae la accuracy bajo ataques FGSM?\n",
    "    > [Respuesta]\n",
    "\n",
    "- ¿PGD empeoró con FGSM training? ¿Por qué?\n",
    "    > [Respuesta]\n",
    "\n",
    "- ¿Cuánto mejora el adversarial training la robustez?\n",
    "    > [Respuesta]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Compromisos\n",
    "\n",
    "- ¿El modelo robusto perdió accuracy limpia? ¿Cuánto?\n",
    "    > [Respuesta]\n",
    "\n",
    "- ¿Vale la pena el Compromisos para aplicaciones reales?\n",
    "    > [Respuesta]\n",
    "\n",
    "- ¿En qué casos recomendarías usar adversarial training?\n",
    "    > [Respuesta]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONCLUSIONES\n",
    "\n",
    "En esta práctica hemos:\n",
    "1. Verificado invariantes del modelo con property-based testing\n",
    "2. Validado rendimiento estadísticamente con intervalos de confianza\n",
    "3. Expuesto la vulnerabilidad extrema a ataques adversarios\n",
    "4. Logrado robustez mediante adversarial training\n",
    "\n",
    "**Reflexión final**: La validación rigurosa —incluyendo robustez adversaria— es crítica antes de desplegar modelos en producción. Un modelo preciso pero vulnerable es un sistema inseguro."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia_confiable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
